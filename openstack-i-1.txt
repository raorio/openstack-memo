
TODO
	問題
		インスタンスへ、cn-1-1から通信できるが、clc-1からはできない。
	dashborad以降のインストール

refer
	openstack install manual
		http://docs.openstack.org/icehouse/install-guide/install/yum/content/

	icehouse rdo
		clc-1
			os: centos 6.5 x86_64
			cpu: 2
			memory: 4 GB
			disk: 40 GB
			3nic:
				eth0: 192.168.116.91(nat)
				eth1: 192.168.10.91(bridge)
				eth2: 192.168.238.91(host only)
			install: dvd1
				root password: user1
				user: user1
				user password: user1
			setup:
				login root
				必要があればproxy設定
					vi /etc/yum.conf
						http_proxy=
				vi /etc/hosts
					#192.168.116.91 openstack-i-clc-1
					192.168.10.91 openstack-i-clc-1
					#192.168.238.91 openstack-i-clc-1
					192.168.10,92 openstack-i-cn-1-1
					192.168.10,93 openstack-i-cn-1-2
				vi /etc/sysconfig/network
					NETWORKING=yes
					#HOSTNAME=localhost.localdomain
					HOSTNAME=openstack-i-clc-1
				vi /etc/sysconfig/network-scripts/ifcfg-eth0
					DEVICE="eth0"
					#BOOTPROTO="dhcp"
					BOOTPROTO="static"
					HWADDR="00:0C:29:BC:06:E5"
					IPV6INIT="yes"
					NM_CONTROLLED="yes"
					ONBOOT="yes"
					TYPE="Ethernet"
					UUID="7fce2f22-528c-4915-901e-4f90f014ecc4"
					IPADDR=192.168.116.91
					PREFIX=24
				vi /etc/sysconfig/network-scripts/ifcfg-eth1
					EVICE=eth1
					HWADDR=00:0C:29:BC:06:EF
					TYPE=Ethernet
					UUID=f4907d33-7c50-4cd0-90ca-e0a83d551a40
					ONBOOT=yes
					NM_CONTROLLED=yes
					#BOOTPROTO=dhcp
					BOOTPROTO=static
					IPADDR=192.168.10.91
					PREFIX=24
					GATEWAY=192.168.10.1
					DNS1=192.168.10.1
				vi /etc/sysconfig/network-scripts/ifcfg-eth2
					DEVICE=eth2
					HWADDR=00:0C:29:BC:06:F9
					TYPE=Ethernet
					UUID=ce1967ce-a970-4ce1-98d4-acd8cf617829
					ONBOOT=yes
					#NM_CONTROLLED=yes
					#BOOTPROTO=dhcp
					BOOTPROTO=static
					IPADDR=192.168.238.91
					PREFIX=24
				reboot
				
				setenforce 0
				getenforce
				vi /etc/selinux/config
					SELINUX=premissive
				
				バックアップ作成：yyyymmdd_os_installed
				
				service NetworkManager stop
				service network start
				chkconfig NetworkManager off
				chkconfig network on
				
				yum -y install ntp
				service ntpd start
				chkconfig ntpd on
				
				yum -y install mysql mysql-server MySQL-python
				vi /etc/my.cnf
					bind-address = 0.0.0.0
					default-storage-engine = innodb
					innodb_file_per_table
					collation-server = utf8_general_ci
					init-connect = 'SET NAMES utf8'
					character-set-server = utf8
				service mysqld start
				chkconfig mysqld on
				mysql_install_db
				mysql_secure_installation
					user1
				
				yum -y install yum-plugin-priorities
				yum -y install http://repos.fedorapeople.org/repos/openstack/openstack-icehouse/rdo-release-icehouse-3.noarch.rpm
				yum -y install http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm
				yum -y install openstack-utils
				yum -y install openstack-selinux
				yum -y upgrade
				reboot
				
				yum -y install qpid-cpp-server
				vi /etc/qpidd.conf
					auth=no
				service qpidd start
				chkconfig qpidd on
				
			http://docs.openstack.org/icehouse/install-guide/install/yum/content/ch_keystone.html
				yum -y install openstack-keystone python-keystoneclient
				
				openstack-config --set /etc/keystone/keystone.conf database connection mysql://keystone:KEYSTONE_DBPASS@openstack-i-clc-1/keystone
				
				mysql -u root -puser1
					CREATE DATABASE keystone;
					GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'localhost' IDENTIFIED BY 'KEYSTONE_DBPASS';
					GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'%' IDENTIFIED BY 'KEYSTONE_DBPASS';
					exit
				
				su -s /bin/sh -c "keystone-manage db_sync" keystone
				
				#ADMIN_TOKEN=$(openssl rand -hex 10)
				#echo $ADMIN_TOKEN
				#openstack-config --set /etc/keystone/keystone.conf DEFAULT admin_token $ADMIN_TOKEN
				openstack-config --set /etc/keystone/keystone.conf DEFAULT admin_token ADMIN_TOKEN
				
				keystone-manage pki_setup --keystone-user keystone --keystone-group keystone
				chown -R keystone:keystone /etc/keystone/ssl
				chmod -R o-rwx /etc/keystone/ssl
				
				service openstack-keystone start
				chkconfig openstack-keystone on
				
				(crontab -l -u keystone 2>&1 | grep -q token_flush) || echo '@hourly /usr/bin/keystone-manage token_flush >/var/log/keystone/keystone-tokenflush.log 2>&1' >> /var/spool/cron/keystone
				
				export OS_SERVICE_TOKEN=ADMIN_TOKEN
				export OS_SERVICE_ENDPOINT=http://openstack-i-clc-1:35357/v2.0
				
				keystone user-create --name=admin --pass=ADMIN_PASS --email=ADMIN_EMAIL
				keystone role-create --name=admin
				keystone tenant-create --name=admin --description="Admin Tenant"
				keystone user-role-add --user=admin --tenant=admin --role=admin
				keystone user-role-add --user=admin --role=_member_ --tenant=admin
				
				keystone user-create --name=demo --pass=DEMO_PASS --email=DEMO_EMAIL
				keystone tenant-create --name=demo --description="Demo Tenant"
				keystone user-role-add --user=demo --role=_member_ --tenant=demo
				
				keystone tenant-create --name=service --description="Service Tenant"
				
				keystone service-create --name=keystone --type=identity --description="OpenStack Identity"
				
				keystone endpoint-create --service-id=$(keystone service-list | awk '/ identity / {print $2}') --publicurl=http://openstack-i-clc-1:5000/v2.0 --internalurl=http://openstack-i-clc-1:5000/v2.0 --adminurl=http://openstack-i-clc-1:35357/v2.0
				
				unset OS_SERVICE_TOKEN OS_SERVICE_ENDPOINT
				
				keystone --os-username=admin --os-password=ADMIN_PASS --os-auth-url=http://openstack-i-clc-1:35357/v2.0 token-get
				keystone --os-username=admin --os-password=ADMIN_PASS --os-tenant-name=admin --os-auth-url=http://openstack-i-clc-1:35357/v2.0 token-get
				
				vi admin-openrc.sh
					export OS_USERNAME=admin
					export OS_PASSWORD=ADMIN_PASS
					export OS_TENANT_NAME=admin
					export OS_AUTH_URL=http://openstack-i-clc-1:35357/v2.0
				
				source admin-openrc.sh
				
				keystone token-get
				
				keystone user-list
				
				keystone user-role-list --user admin --tenant admin
				
			http://docs.openstack.org/icehouse/install-guide/install/yum/content/ch_clients.html
				allmost skip
				
				vi demo-openrc.sh
					export OS_USERNAME=demo
					export OS_PASSWORD=DEMO_PASS
					export OS_TENANT_NAME=demo
					export OS_AUTH_URL=http://openstack-i-clc-1:35357/v2.0
				
			http://docs.openstack.org/icehouse/install-guide/install/yum/content/ch_glance.html
				yum -y install openstack-glance python-glanceclient
				
				openstack-config --set /etc/glance/glance-api.conf database connection mysql://glance:GLANCE_DBPASS@openstack-i-clc-1/glance
				openstack-config --set /etc/glance/glance-registry.conf database connection mysql://glance:GLANCE_DBPASS@openstack-i-clc-1/glance
				
				openstack-config --set /etc/glance/glance-api.conf DEFAULT rpc_backend qpid
				openstack-config --set /etc/glance/glance-api.conf DEFAULT qpid_hostname openstack-i-clc-1
				
				mysql -u root -puser1
					CREATE DATABASE glance;
					GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'localhost' IDENTIFIED BY 'GLANCE_DBPASS';
					GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'%' IDENTIFIED BY 'GLANCE_DBPASS';
					exit;
				
				su -s /bin/sh -c "glance-manage db_sync" glance
				
				keystone user-create --name=glance --pass=GLANCE_PASS --email=glance@example.com
				keystone user-role-add --user=glance --tenant=service --role=admin
				
				openstack-config --set /etc/glance/glance-api.conf keystone_authtoken auth_uri http://openstack-i-clc-1:5000
				openstack-config --set /etc/glance/glance-api.conf keystone_authtoken auth_host openstack-i-clc-1
				openstack-config --set /etc/glance/glance-api.conf keystone_authtoken auth_port 35357
				openstack-config --set /etc/glance/glance-api.conf keystone_authtoken auth_protocol http
				openstack-config --set /etc/glance/glance-api.conf keystone_authtoken admin_tenant_name service
				openstack-config --set /etc/glance/glance-api.conf keystone_authtoken admin_user glance
				openstack-config --set /etc/glance/glance-api.conf keystone_authtoken admin_password GLANCE_PASS
				openstack-config --set /etc/glance/glance-api.conf paste_deploy flavor keystone
				openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken auth_uri http://openstack-i-clc-1:5000
				openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken auth_host openstack-i-clc-1
				openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken auth_port 35357
				openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken auth_protocol http
				openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken admin_tenant_name service
				openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken admin_user glance
				openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken admin_password GLANCE_PASS
				openstack-config --set /etc/glance/glance-registry.conf paste_deploy flavor keystone
				
				keystone service-create --name=glance --type=image --description="OpenStack Image Service"
				keystone endpoint-create --service-id=$(keystone service-list | awk '/ image / {print $2}') --publicurl=http://openstack-i-clc-1:9292 --internalurl=http://openstack-i-clc-1:9292 --adminurl=http://openstack-i-clc-1:9292
				
				service openstack-glance-api start
				service openstack-glance-registry start
				chkconfig openstack-glance-api on
				chkconfig openstack-glance-registry on
				
				mkdir images
				cd images/
				wget http://cdn.download.cirros-cloud.net/0.3.2/cirros-0.3.2-x86_64-disk.img
				glance image-create --name "cirros-0.3.2-x86_64" --disk-format qcow2 --container-format bare --is-public True --progress < cirros-0.3.2-x86_64-disk.img
				
				glance image-list
				
			http://docs.openstack.org/icehouse/install-guide/install/yum/content/nova-controller.html
				yum -y install openstack-nova-api openstack-nova-cert openstack-nova-conductor openstack-nova-console openstack-nova-novncproxy openstack-nova-scheduler python-novaclient
				
				openstack-config --set /etc/nova/nova.conf database connection mysql://nova:NOVA_DBPASS@openstack-i-clc-1/nova
				
				openstack-config --set /etc/nova/nova.conf DEFAULT rpc_backend qpid
				openstack-config --set /etc/nova/nova.conf DEFAULT qpid_hostname openstack-i-clc-1
				
				openstack-config --set /etc/nova/nova.conf DEFAULT my_ip 192.168.10.91
				openstack-config --set /etc/nova/nova.conf DEFAULT vncserver_listen 192.168.10.91
				openstack-config --set /etc/nova/nova.conf DEFAULT vncserver_proxyclient_address 192.168.10.91
				
				mysql -u root -puser1
					CREATE DATABASE nova;
					GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'localhost' IDENTIFIED BY 'NOVA_DBPASS';
					GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'%' IDENTIFIED BY 'NOVA_DBPASS';
					exit;
				
				su -s /bin/sh -c "nova-manage db sync" nova
				
				keystone user-create --name=nova --pass=NOVA_PASS --email=nova@example.com
				keystone user-role-add --user=nova --tenant=service --role=admin
				
				openstack-config --set /etc/nova/nova.conf DEFAULT auth_strategy keystone
				openstack-config --set /etc/nova/nova.conf keystone_authtoken auth_uri http://openstack-i-clc-1:5000
				openstack-config --set /etc/nova/nova.conf keystone_authtoken auth_host openstack-i-clc-1
				openstack-config --set /etc/nova/nova.conf keystone_authtoken auth_protocol http
				openstack-config --set /etc/nova/nova.conf keystone_authtoken auth_port 35357
				openstack-config --set /etc/nova/nova.conf keystone_authtoken admin_user nova
				openstack-config --set /etc/nova/nova.conf keystone_authtoken admin_tenant_name service
				openstack-config --set /etc/nova/nova.conf keystone_authtoken admin_password NOVA_PASS
				
				keystone service-create --name=nova --type=compute --description="OpenStack Compute"
				keystone endpoint-create --service-id=$(keystone service-list | awk '/ compute / {print $2}') --publicurl=http://openstack-i-clc-1:8774/v2/%\(tenant_id\)s --internalurl=http://openstack-i-clc-1:8774/v2/%\(tenant_id\)s --adminurl=http://openstack-i-clc-1:8774/v2/%\(tenant_id\)s
				
				service openstack-nova-api start
				service openstack-nova-cert start
				service openstack-nova-consoleauth start
				service openstack-nova-scheduler start
				service openstack-nova-conductor start
				service openstack-nova-novncproxy start
				chkconfig openstack-nova-api on
				chkconfig openstack-nova-cert on
				chkconfig openstack-nova-consoleauth on
				chkconfig openstack-nova-scheduler on
				chkconfig openstack-nova-conductor on
				chkconfig openstack-nova-novncproxy on
				
				nova image-list
				
				バックアップ：20140710_nova_installed
				
				/etc/hostsの誤記を修正
				vi /ets/hosts
					192.168.10.92 openstack-i-cn-1-1
					192.168.10.93 openstack-i-cn-1-2
				
				GUIでfirewall off
		
		cn-1-1
			os: centos 6.5 x86_64
			cpu: 2
			memory: 4 GB
			disk: 40 GB
			disk: 40 GB
			3nic:
				eth0: 192.168.116.92(nat)
				eth1: 192.168.10.92(bridge)
				eth2: 192.168.238.92(host only)
			install: dvd1
				root password: user1
				user: user1
				user password: user1
			setup:
				login root
				必要があればproxy設定
					vi /etc/yum.conf
						http_proxy=
				vi /etc/hosts
					#192.168.116.91 openstack-i-clc-1
					192.168.10.91 openstack-i-clc-1
					#192.168.238.91 openstack-i-clc-1
					192.168.10,92 openstack-i-cn-1-1
					192.168.10,93 openstack-i-cn-1-2
				vi /etc/sysconfig/network
					NETWORKING=yes
					#HOSTNAME=localhost.localdomain
					HOSTNAME=openstack-i-cn-1-1
				vi /etc/sysconfig/network-scripts/ifcfg-eth0
					DEVICE="eth0"
					#BOOTPROTO="dhcp"
					BOOTPROTO="static"
					HWADDR="00:0C:29:BC:06:E5"
					IPV6INIT="yes"
					NM_CONTROLLED="yes"
					ONBOOT="yes"
					TYPE="Ethernet"
					UUID="7fce2f22-528c-4915-901e-4f90f014ecc4"
					IPADDR=192.168.116.92
					PREFIX=24
				vi /etc/sysconfig/network-scripts/ifcfg-eth1
					EVICE=eth1
					HWADDR=00:0C:29:BC:06:EF
					TYPE=Ethernet
					UUID=f4907d33-7c50-4cd0-90ca-e0a83d551a40
					ONBOOT=yes
					NM_CONTROLLED=yes
					#BOOTPROTO=dhcp
					BOOTPROTO=static
					IPADDR=192.168.10.92
					PREFIX=24
					GATEWAY=192.168.10.1
					DNS1=192.168.10.1
				vi /etc/sysconfig/network-scripts/ifcfg-eth2
					DEVICE=eth2
					HWADDR=00:0C:29:BC:06:F9
					TYPE=Ethernet
					UUID=ce1967ce-a970-4ce1-98d4-acd8cf617829
					ONBOOT=yes
					#NM_CONTROLLED=yes
					#BOOTPROTO=dhcp
					#BOOTPROTO=static
					BOOTPROTO=none
					#IPADDR=192.168.238.92
					#PREFIX=24
				reboot
				
				setenforce 0
				getenforce
				vi /etc/selinux/config
					SELINUX=premissive
				
				バックアップ作成：yyyymmdd_os_installed
				
				service NetworkManager stop
				service network start
				chkconfig NetworkManager off
				chkconfig network on
				
				yum -y install ntp
				service ntpd start
				chkconfig ntpd on
				
				yum -y install MySQL-python

				yum -y install yum-plugin-priorities
				yum -y install http://repos.fedorapeople.org/repos/openstack/openstack-icehouse/rdo-release-icehouse-3.noarch.rpm
				yum -y install http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm
				yum -y install openstack-utils
				yum -y install openstack-selinux
				yum -y upgrade
				reboot
				
			http://docs.openstack.org/icehouse/install-guide/install/yum/content/nova-compute.html
				yum -y install openstack-nova-compute
				
				openstack-config --set /etc/nova/nova.conf database connection mysql://nova:NOVA_DBPASS@openstack-i-clc-1/nova
				openstack-config --set /etc/nova/nova.conf DEFAULT auth_strategy keystone
				openstack-config --set /etc/nova/nova.conf keystone_authtoken auth_uri http://openstack-i-clc-1:5000
				openstack-config --set /etc/nova/nova.conf keystone_authtoken auth_host openstack-i-clc-1
				openstack-config --set /etc/nova/nova.conf keystone_authtoken auth_protocol http
				openstack-config --set /etc/nova/nova.conf keystone_authtoken auth_port 35357
				openstack-config --set /etc/nova/nova.conf keystone_authtoken admin_user nova
				openstack-config --set /etc/nova/nova.conf keystone_authtoken admin_tenant_name service
				openstack-config --set /etc/nova/nova.conf keystone_authtoken admin_password NOVA_PASS
				
				openstack-config --set /etc/nova/nova.conf DEFAULT rpc_backend qpid
				openstack-config --set /etc/nova/nova.conf DEFAULT qpid_hostname openstack-i-clc-1
				
				openstack-config --set /etc/nova/nova.conf DEFAULT my_ip 192.168.10.92
				openstack-config --set /etc/nova/nova.conf DEFAULT vnc_enabled True
				openstack-config --set /etc/nova/nova.conf DEFAULT vncserver_listen 0.0.0.0
				openstack-config --set /etc/nova/nova.conf DEFAULT vncserver_proxyclient_address 192.168.10.92
				openstack-config --set /etc/nova/nova.conf DEFAULT novncproxy_base_url http://openstack-i-clc-1:6080/vnc_auto.html
				
				openstack-config --set /etc/nova/nova.conf DEFAULT glance_host openstack-i-clc-1
				
				egrep -c '(vmx|svm)' /proc/cpuinfo
				
				#openstack-config --set /etc/nova/nova.conf libvirt virt_type qemu
				
				service libvirtd start
				service messagebus start
				service openstack-nova-compute start
				chkconfig libvirtd on
				chkconfig messagebus on
				chkconfig openstack-nova-compute on
				
				バックアップ：20140710_nova_installed
				
				/etc/hostsの誤記を修正
				vi /ets/hosts
					192.168.10.92 openstack-i-cn-1-1
					192.168.10.93 openstack-i-cn-1-2
				
				GUIでfirewall off

		clc-1
			http://docs.openstack.org/icehouse/install-guide/install/yum/content/nova-networking-controller-node.html
				
				openstack-config --set /etc/nova/nova.conf DEFAULT network_api_class nova.network.api.API
				openstack-config --set /etc/nova/nova.conf DEFAULT security_group_api nova
				
				service openstack-nova-api restart
				service openstack-nova-scheduler restart
				service openstack-nova-conductor restart
				
		cn-1-1
			http://docs.openstack.org/icehouse/install-guide/install/yum/content/nova-networking-compute-node.html
				
				yum -y install openstack-nova-network openstack-nova-api
				
				openstack-config --set /etc/nova/nova.conf DEFAULT network_api_class nova.network.api.API
				openstack-config --set /etc/nova/nova.conf DEFAULT security_group_api nova
				openstack-config --set /etc/nova/nova.conf DEFAULT network_manager nova.network.manager.FlatDHCPManager
				openstack-config --set /etc/nova/nova.conf DEFAULT firewall_driver nova.virt.libvirt.firewall.IptablesFirewallDriver
				openstack-config --set /etc/nova/nova.conf DEFAULT network_size 254
				openstack-config --set /etc/nova/nova.conf DEFAULT allow_same_net_traffic False
				openstack-config --set /etc/nova/nova.conf DEFAULT multi_host True
				openstack-config --set /etc/nova/nova.conf DEFAULT send_arp_for_ha True
				openstack-config --set /etc/nova/nova.conf DEFAULT share_dhcp_address True
				openstack-config --set /etc/nova/nova.conf DEFAULT force_dhcp_release True
				openstack-config --set /etc/nova/nova.conf DEFAULT flat_network_bridge br100
				openstack-config --set /etc/nova/nova.conf DEFAULT flat_interface eth2
				openstack-config --set /etc/nova/nova.conf DEFAULT public_interface eth1
				
				service openstack-nova-network start
				service openstack-nova-metadata-api start
				chkconfig openstack-nova-network on
				chkconfig openstack-nova-metadata-api on
				
		clc-1
			http://docs.openstack.org/icehouse/install-guide/install/yum/content/nova-network-initial-network.html
				
				source admin-openrc.sh
				
				nova network-create demo-net --bridge br100 --multi-host T --fixed-range-v4 192.168.238.24/29
				
				nova net-list
				
			http://docs.openstack.org/icehouse/install-guide/install/yum/content/launch-instance-nova.html
				
				source demo-openrc.sh
				
				nova flavor-list
				
				nova image-list
				
				nova net-list
				
				nova secgroup-list
				
				nova boot --flavor m1.tiny --image cirros-0.3.2-x86_64 --nic net-id=56cc602b-ed28-4f45-987a-1338471a955b --security-group default demo-instance1
				
				nova get-vnc-console demo-instance1 novnc
				
				nova secgroup-add-rule default icmp -1 -1 0.0.0.0/0
				
				nova secgroup-add-rule default tcp 1 65535 0.0.0.0/0
				
				nova secgroup-add-rule default udp 1 65535 0.0.0.0/0
				
				compute nodeからインスタンスにping/sshが接続できることを確認。
				
			http://docs.openstack.org/icehouse/install-guide/install/yum/content/ch_horizon.html
				
				yum -y install memcached python-memcached mod_wsgi openstack-dashboard
				
				vi /etc/openstack-dashboard/local_settings
					CACHES = {
					'default': {
					'BACKEND' : 'django.core.cache.backends.memcached.MemcachedCache',
					'LOCATION' : '127.0.0.1:11211'
					}
					}
					...(略)
					ALLOWED_HOSTS = ['localhost', '192.168.10.91']
					...(略)
					#OPENSTACK_HOST = "127.0.0.1"
					OPENSTACK_HOST = "openstack-i-clc-1"
				
				setsebool -P httpd_can_network_connect on
				
				service httpd start
				service memcached start
				chkconfig httpd on
				chkconfig memcached on
				
				service httpd restart
				service memcached restart
				
		client
				http://192.168.10.91/dashboard
				
		cn-1-1
			バックアップ：20140716_dashborad_installed
			
		clc-1
			バックアップ：20140716_dashborad_installed
			
		clc-1
			http://docs.openstack.org/icehouse/install-guide/install/yum/content/dashboard-sessions.html
				TODO 保留 未実施
			
				vi /etc/openstack-dashboard/local_settings
					SESSION_ENGINE = 'django.contrib.sessions.backends.cache'
					CACHES = {
					  'default' : {
					    'BACKEND': 'django.core.cache.backends.locmem.LocMemCache'
					  }
					}
			
			
		clc-1
			http://docs.openstack.org/icehouse/install-guide/install/yum/content/cinder-controller.html
			
				yum -y install openstack-cinder
				
				openstack-config --set /etc/cinder/cinder.conf database connection mysql://cinder:CINDER_DBPASS@openstack-i-clc-1/cinder
				
				mysql -u root -puser1
					CREATE DATABASE cinder;
					GRANT ALL PRIVILEGES ON cinder.* TO 'cinder'@'localhost' IDENTIFIED BY 'CINDER_DBPASS';
					GRANT ALL PRIVILEGES ON cinder.* TO 'cinder'@'%' IDENTIFIED BY 'CINDER_DBPASS';
					exit;
				
				su -s /bin/sh -c "cinder-manage db sync" cinder
				
				keystone user-create --name=cinder --pass=CINDER_PASS --email=cinder@example.com
					+----------+----------------------------------+
					| Property |              Value               |
					+----------+----------------------------------+
					|  email   |        cinder@example.com        |
					| enabled  |               True               |
					|    id    | 6d0c8991da66420ca14bd3ef22c90025 |
					|   name   |              cinder              |
					| username |              cinder              |
					+----------+----------------------------------+
				keystone user-role-add --user=cinder --tenant=service --role=admin
				
				openstack-config --set /etc/cinder/cinder.conf DEFAULT auth_strategy keystone
				openstack-config --set /etc/cinder/cinder.conf keystone_authtoken auth_uri http://openstack-i-clc-1:5000
				openstack-config --set /etc/cinder/cinder.conf keystone_authtoken auth_host openstack-i-clc-1
				openstack-config --set /etc/cinder/cinder.conf keystone_authtoken auth_protocol http
				openstack-config --set /etc/cinder/cinder.conf keystone_authtoken auth_port 35357
				openstack-config --set /etc/cinder/cinder.conf keystone_authtoken admin_user cinder
				openstack-config --set /etc/cinder/cinder.conf keystone_authtoken admin_tenant_name service
				openstack-config --set /etc/cinder/cinder.conf keystone_authtoken admin_password CINDER_PASS
				
				openstack-config --set /etc/cinder/cinder.conf DEFAULT rpc_backend cinder.openstack.common.rpc.impl_qpid
				openstack-config --set /etc/cinder/cinder.conf DEFAULT qpid_hostname openstack-i-clc-1
				
				keystone service-create --name=cinder --type=volume --description="OpenStack Block Storage"
					+-------------+----------------------------------+
					|   Property  |              Value               |
					+-------------+----------------------------------+
					| description |     OpenStack Block Storage      |
					|   enabled   |               True               |
					|      id     | ffb81baf2ac44aedb62028f988bd2d1e |
					|     name    |              cinder              |
					|     type    |              volume              |
					+-------------+----------------------------------+
				keystone endpoint-create --service-id=$(keystone service-list | awk '/ volume / {print $2}') --publicurl=http://openstack-i-clc-1:8776/v1/%\(tenant_id\)s --internalurl=http://openstack-i-clc-1:8776/v1/%\(tenant_id\)s --adminurl=http://openstack-i-clc-1:8776/v1/%\(tenant_id\)s
					+-------------+------------------------------------------------+
					|   Property  |                     Value                      |
					+-------------+------------------------------------------------+
					|   adminurl  | http://openstack-i-clc-1:8776/v1/%(tenant_id)s |
					|      id     |        80825b4095744aa19a75dd61ff98cd07        |
					| internalurl | http://openstack-i-clc-1:8776/v1/%(tenant_id)s |
					|  publicurl  | http://openstack-i-clc-1:8776/v1/%(tenant_id)s |
					|    region   |                   regionOne                    |
					|  service_id |        ffb81baf2ac44aedb62028f988bd2d1e        |
					+-------------+------------------------------------------------+
				
				keystone service-create --name=cinderv2 --type=volumev2 --description="OpenStack Block Storage v2"
					+-------------+----------------------------------+
					|   Property  |              Value               |
					+-------------+----------------------------------+
					| description |    OpenStack Block Storage v2    |
					|   enabled   |               True               |
					|      id     | a3f35833843040ddb4cee75af5fcc325 |
					|     name    |             cinderv2             |
					|     type    |             volumev2             |
					+-------------+----------------------------------+
				keystone endpoint-create --service-id=$(keystone service-list | awk '/ volumev2 / {print $2}') --publicurl=http://openstack-i-clc-1:8776/v2/%\(tenant_id\)s --internalurl=http://openstack-i-clc-1:8776/v2/%\(tenant_id\)s --adminurl=http://openstack-i-clc-1:8776/v2/%\(tenant_id\)s
					+-------------+------------------------------------------------+
					|   Property  |                     Value                      |
					+-------------+------------------------------------------------+
					|   adminurl  | http://openstack-i-clc-1:8776/v2/%(tenant_id)s |
					|      id     |        516bb38392b44b97ad0ba61dd483904a        |
					| internalurl | http://openstack-i-clc-1:8776/v2/%(tenant_id)s |
					|  publicurl  | http://openstack-i-clc-1:8776/v2/%(tenant_id)s |
					|    region   |                   regionOne                    |
					|  service_id |        a3f35833843040ddb4cee75af5fcc325        |
					+-------------+------------------------------------------------+
				
				service openstack-cinder-api start
				service openstack-cinder-scheduler start
				chkconfig openstack-cinder-api on
				chkconfig openstack-cinder-scheduler on
		
		cn-1-1
			http://docs.openstack.org/icehouse/install-guide/install/yum/content/cinder-node.html
			
				pvcreate /dev/sdb
				vgcreate cinder-volumes /dev/sdb
				
				vi /etc/lvm/lvm.conf
					devices {
					...
					filter = [ "a/sda1/", "a/sdb/", "r/.*/"]
					...
					}
				
				pvdisplay
					  --- Physical volume ---
					  PV Name               /dev/sdb
					  VG Name               cinder-volumes
					  PV Size               40.00 GiB / not usable 4.00 MiB
					  Allocatable           yes
					  PE Size               4.00 MiB
					  Total PE              10239
					  Free PE               10239
					  Allocated PE          0
					  PV UUID               rIJBoz-O2aa-MlhK-b0eh-UsB0-s8M0-eSPRfj
				
				yum -y install openstack-cinder scsi-target-utils
				
				openstack-config --set /etc/cinder/cinder.conf DEFAULT auth_strategy keystone
				openstack-config --set /etc/cinder/cinder.conf keystone_authtoken auth_uri http://openstack-i-clc-1:5000
				openstack-config --set /etc/cinder/cinder.conf keystone_authtoken auth_host openstack-i-clc-1
				openstack-config --set /etc/cinder/cinder.conf keystone_authtoken auth_protocol http
				openstack-config --set /etc/cinder/cinder.conf keystone_authtoken auth_port 35357
				openstack-config --set /etc/cinder/cinder.conf keystone_authtoken admin_user cinder
				openstack-config --set /etc/cinder/cinder.conf keystone_authtoken admin_tenant_name service
				openstack-config --set /etc/cinder/cinder.conf keystone_authtoken admin_password CINDER_PASS
				
				openstack-config --set /etc/cinder/cinder.conf DEFAULT rpc_backend cinder.openstack.common.rpc.impl_qpid
				openstack-config --set /etc/cinder/cinder.conf DEFAULT qpid_hostname openstack-i-clc-1
				
				openstack-config --set /etc/cinder/cinder.conf database connection mysql://cinder:CINDER_DBPASS@openstack-i-clc-1/cinder
				
				openstack-config --set /etc/cinder/cinder.conf DEFAULT glance_host openstack-i-clc-1
				
				vi /etc/tgt/targets.conf
					include /etc/cinder/volumes/*
				
				service openstack-cinder-volume start
				service tgtd start
				chkconfig openstack-cinder-volume on
				chkconfig tgtd on
				
				vgdisplay
				
		clc-1
			http://docs.openstack.org/icehouse/install-guide/install/yum/content/cinder-verify.html
				source demo-openrc.sh
				
				cinder create --display-name myVolume 1
					+---------------------+--------------------------------------+
					|       Property      |                Value                 |
					+---------------------+--------------------------------------+
					|     attachments     |                  []                  |
					|  availability_zone  |                 nova                 |
					|       bootable      |                false                 |
					|      created_at     |      2014-08-30T13:42:47.303373      |
					| display_description |                 None                 |
					|     display_name    |               myVolume               |
					|      encrypted      |                False                 |
					|          id         | 63357a8b-9e68-4331-b098-b5db2e844cfe |
					|       metadata      |                  {}                  |
					|         size        |                  1                   |
					|     snapshot_id     |                 None                 |
					|     source_volid    |                 None                 |
					|        status       |               creating               |
					|     volume_type     |                 None                 |
					+---------------------+--------------------------------------+
				
				cinder list
					+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+
					|                  ID                  |   Status  | Display Name | Size | Volume Type | Bootable | Attached to |
					+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+
					| 63357a8b-9e68-4331-b098-b5db2e844cfe | available |   myVolume   |  1   |     None    |  false   |             |
					+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+
				
		cn-1-1
				vgdisplay
					  --- Volume group ---
					  VG Name               cinder-volumes
					  System ID
					  Format                lvm2
					  Metadata Areas        1
					  Metadata Sequence No  2
					  VG Access             read/write
					  VG Status             resizable
					  MAX LV                0
					  Cur LV                1
					  Open LV               0
					  Max PV                0
					  Cur PV                1
					  Act PV                1
					  VG Size               40.00 GiB
					  PE Size               4.00 MiB
					  Total PE              10239
					  Alloc PE / Size       256 / 1.00 GiB
					  Free  PE / Size       9983 / 39.00 GiB
					  VG UUID               LoM1du-Iheu-dSRv-VYVD-xxVz-n9RU-0XS5ju
				
				インスタンスを作成しておく
					...(略)
				
				nova list
					+--------------------------------------+----------------+--------+------------+-------------+-------------------------+
					| ID                                   | Name           | Status | Task State | Power State | Networks                |
					+--------------------------------------+----------------+--------+------------+-------------+-------------------------+
					| 9219923a-c335-4752-8434-10a5cbbb0e22 | demo-instance1 | ACTIVE | -          | Running     | demo-net=192.168.238.26 |
					+--------------------------------------+----------------+--------+------------+-------------+-------------------------+
				
				nova volume-attach demo-instance1 63357a8b-9e68-4331-b098-b5db2e844cfe /dev/vdc
				
				インスタンスに接続し、スーパーユーザになる
					...(略)
					
					ls /dev/vd*
						/dev/vda   /dev/vda1  /dev/vdb
					fdisk /dev/vdb
						新しいディスクを作成
							...(略)
					
					ls /dev/vd*
						/dev/vda   /dev/vda1  /dev/vdb   /dev/vdb1
					mkfs.ext4 /dev/vdb1
					mount -t ext4 /dev/vdb1 /mnt/vdb1
				
			ボリュームの接続方法
				ls -l /dev/disk/by-path/ip-192.168.10.92\:3260-iscsi-iqn.2010-10.org.openstack\:volume-63357a8b-9e68-4331-b098-b5db2e844cfe-lun-1
					lrwxrwxrwx. 1 root root 9 Aug 30 07:03 /dev/disk/by-path/ip-192.168.10.92:3260-iscsi-iqn.2010-10.org.openstack:volume-63357a8b-9e68-4331-b098-b5db2e844cfe-lun-  -> ../../sdc
				ls /dev/sdc -la
					brw-rw----. 1 qemu qemu 8, 32 Aug 30 07:13 /dev/sdc
				アタッチ済みのボリュームは、/dev/sdcとして見えている。
				
				nova volume-detach demo-instance1 63357a8b-9e68-4331-b098-b5db2e844cfe
			
			ボリュームのバックアップ方法
				upload-to-image
					Upload volume to image service as image.
					http://docs.openstack.org/user-guide/content/cinderclient_commands.html
						cinder upload-to-image [--force <True|False>]
							[--container-format <container-format>]
							[--disk-format <disk-format>]
							<volume> <image-name>
					
					cinder upload-to-image 63357a8b-9e68-4331-b098-b5db2e844cfe myVolume-upload-1
						ERROR: Invalid volume: Volume status is in-use. (HTTP 400) (Request-ID: req-170f94a5-3a97-4a9d-aa10-5558288261e7)
							statusがin-useだとエラーとなる。この場合、forceオプションを付ければよい。
					cinder upload-to-image --force True 63357a8b-9e68-4331-b098-b5db2e844cfe myVolume-upload-1
						+---------------------+--------------------------------------+
						|       Property      |                Value                 |
						+---------------------+--------------------------------------+
						|   container_format  |                 bare                 |
						|     disk_format     |                 raw                  |
						| display_description |                 None                 |
						|          id         | 63357a8b-9e68-4331-b098-b5db2e844cfe |
						|       image_id      | 88f1dbc3-ac19-4095-b950-4832f31f5fd6 |
						|      image_name     |          myVolume-upload-1           |
						|         size        |                  1                   |
						|        status       |              uploading               |
						|      updated_at     |      2014-08-30T14:03:41.000000      |
						|     volume_type     |                 None                 |
						+---------------------+--------------------------------------+
					cinder upload-to-image --force True --disk-format qcow2 63357a8b-9e68-4331-b098-b5db2e844cfe myVolume-upload-qcow2-1
						+---------------------+--------------------------------------+
						|       Property      |                Value                 |
						+---------------------+--------------------------------------+
						|   container_format  |                 bare                 |
						|     disk_format     |                qcow2                 |
						| display_description |                 None                 |
						|          id         | 63357a8b-9e68-4331-b098-b5db2e844cfe |
						|       image_id      | 9907b396-c72e-4da1-9de1-01b094364eed |
						|      image_name     |       myVolume-upload-qcow2-1        |
						|         size        |                  1                   |
						|        status       |              uploading               |
						|      updated_at     |      2014-08-30T14:16:24.000000      |
						|     volume_type     |                 None                 |
						+---------------------+--------------------------------------+
					glance index
						ID                                   Name                           Disk Format          Container Format     Size
						------------------------------------ ------------------------------ -------------------- -------------------- --------------
						9907b396-c72e-4da1-9de1-01b094364eed myVolume-upload-qcow2-1        qcow2                bare                        1376256
						88f1dbc3-ac19-4095-b950-4832f31f5fd6 myVolume-upload-1              raw                  bare                     1073741824
						52ec8b03-1b9e-4892-91d4-b2d492ff6c19 cirros-0.3.2-x86_64            qcow2                bare                       13167616
					nova image-list
						+--------------------------------------+-------------------------+--------+--------+
						| ID                                   | Name                    | Status | Server |
						+--------------------------------------+-------------------------+--------+--------+
						| 52ec8b03-1b9e-4892-91d4-b2d492ff6c19 | cirros-0.3.2-x86_64     | ACTIVE |        |
						| 88f1dbc3-ac19-4095-b950-4832f31f5fd6 | myVolume-upload-1       | ACTIVE |        |
						| 9907b396-c72e-4da1-9de1-01b094364eed | myVolume-upload-qcow2-1 | ACTIVE |        |
						+--------------------------------------+-------------------------+--------+--------+
					ls -l /var/lib/glance/images/
						total 1061440
						-rw-r-----. 1 glance glance   13167616 Jul 10 06:46 52ec8b03-1b9e-4892-91d4-b2d492ff6c19
						-rw-r-----. 1 glance glance 1073741824 Aug 30 07:16 88f1dbc3-ac19-4095-b950-4832f31f5fd6
					glanceにアップロードされたイメージをkvmでディスクとして接続し参照すると、正しく中身が見えた。
					
				
				backup-create
					http://docs.openstack.org/user-guide/content/cinderclient_commands.html
						cinder backup-create [--container <container>]
							[--display-name <display-name>]
							[--display-description <display-description>]
							<volume>
					http://docs.openstack.org/grizzly/openstack-block-storage/admin/content/block_storage_overview.html
						A Backup is an archived copy of a Volume currently stored in Object Storage (Swift).
							バックアップはSWIFTの中に格納される、現在のボリュームのコピーアーカイブ。とある。
				
				qemu-img
					cinder upload-to-image中に以下プロセスのコマンドが参照できたので、openstack起動しなくても障害時等に使えそう。
						sudo cinder-rootwrap /etc/cinder/rootwrap.conf qemu-img convert -O qcow2 /dev/mapper/cinder--volumes-volume--63357a8b--9e68--4331--b098--b5db2e844cfe /var/lib/cinder/conversion/tmp6kCIxl
					
					qemu-img convert -O qcow2 /dev/mapper/cinder--volumes-volume--63357a8b--9e68--4331--b098--b5db2e844cfe /tmp/disk1.img
					
					/dev/mapper/cinder--volumes-volume--*がcinderが起動していない状態でもできていて、qemu-imgで変換可能かテスト
						chkconfig openstack-cinder-volume off
						reboot
						ps aux | grep cinder
						ls /dev/mapper/cinder--volumes-volume--*
						qemu-img convert -O qcow2 /dev/mapper/cinder--volumes-volume--63357a8b--9e68--4331--b098--b5db2e844cfe /tmp/disk2.img
						ls -la /tmp/disk*.img
							-rw-r--r--. 1 root root 1441792 Aug 30 08:24 /tmp/disk1.img
							-rw-r--r--. 1 root root 1441792 Aug 30 08:33 /tmp/disk2.img
					
					/dev/mapper/cinder--volumes-volume--*がtgtdが起動していない状態でもできていて、qemu-imgで変換可能かテスト
						chkconfig tgtd off
						reboot
						ps aux | grep tgtd
						ls /dev/mapper/cinder--volumes-volume--*
						qemu-img convert -O qcow2 /dev/mapper/cinder--volumes-volume--63357a8b--9e68--4331--b098--b5db2e844cfe /tmp/disk3.img
						ls -la /tmp/disk*.img
							-rw-r--r--. 1 root root 1441792 Aug 30 08:24 /tmp/disk1.img
							-rw-r--r--. 1 root root 1441792 Aug 30 08:33 /tmp/disk2.img
							-rw-r--r--. 1 root root 1441792 Aug 30 08:41 /tmp/disk3.img
				
				バックアップ作成：20140830_cinder_installed
				

